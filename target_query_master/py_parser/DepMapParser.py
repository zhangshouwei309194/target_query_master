import pandas as pd
import numpy as np
import json
import os
import time
from collections import OrderedDict
import dask.dataframe as dd
from typing import Dict, Union

class DepMapParser:
    """
    é¢å‘å¯¹è±¡çš„DepMapæ•°æ®è§£æå™¨
    å°è£…äº†ä»DepMapæ•°æ®æ–‡ä»¶æå–åŸºå› è¡¨è¾¾ä¿¡æ¯ã€è§£æå’Œè½¬æ¢çš„åŠŸèƒ½
    """
    
    def __init__(self,
                 genename=None,
                 sample_expr_file=None, 
                 metadata_file=None):
        """
        åˆå§‹åŒ–TCGAè§£æå™¨
        
        Args:
            genename (str, optional): gene symbol
            sample_expr_file (str): æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®æ–‡ä»¶è·¯å¾„
            metadata_file (str): æ ·æœ¬å…ƒæ•°æ®æ‰€æœ‰ç™Œç—‡ç»†èƒç³»æ ·æœ¬ç±»å‹æ–‡ä»¶è·¯å¾„
        """
        self.genename = genename
        self.sample_expr_file = sample_expr_file
        self.metadata_file = metadata_file
        self.parsed_data = None
        self.processing_time = None
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        if sample_expr_file and not os.path.exists(sample_expr_file):
            raise FileNotFoundError(f"æ ·æœ¬è¡¨è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {sample_expr_file}")
        if metadata_file and not os.path.exists(metadata_file):
            raise FileNotFoundError(f"æ‰€æœ‰ç™Œç—‡æ ·æœ¬ç±»å‹å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")
    
    def extract_gene_expression_dask(self,file_path: str, target_gene: str) -> Dict[str, Union[dd.DataFrame, bool, str]]:
        """
        ä½¿ç”¨Daské«˜æ•ˆè¯»å–åŸºå› è¡¨è¾¾æ•°æ®å¹¶æå–ç›®æ ‡åŸºå› çš„è¡¨è¾¾ä¿¡æ¯
        
        å‚æ•°:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            target_gene: ç›®æ ‡åŸºå› åç§°(å¦‚"TNMD")
        
        è¿”å›:
            å­—å…¸åŒ…å«:
            - 'data': Dask DataFrameåŒ…å«å››åˆ—: Symbol, NCBI_Gene, ModelID, Expression_log
            - 'gene_found': å¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦æˆåŠŸæ‰¾åˆ°åŸºå› 
            - 'error': é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰é”™è¯¯åˆ™ä¸ºç©º
        """
        
        # åˆå§‹åŒ–è¿”å›å­—å…¸
        result = {
            'data': pd.DataFrame(),  # ç©ºDataFrame
            'gene_found': False,
            'error': ''
        }
        
        try:
            # 1. ä½¿ç”¨Pandaså®‰å…¨è¯»å–åˆ—åï¼ˆé¿å…Daskæ ·æœ¬å¤§å°é—®é¢˜ï¼‰
            try:
                print("ä½¿ç”¨Pandasè¯»å–åˆ—å...")
                df_sample = pd.read_csv(file_path, nrows=0)
                all_columns = df_sample.columns.tolist()
                print(f"æˆåŠŸè¯»å– {len(all_columns)} åˆ—")
            except Exception as pd_error:
                result['error'] = f"æ— æ³•è¯»å–æ–‡ä»¶åˆ—å: {pd_error}"
                return result
            
            # 2. æ”¹è¿›åˆ—åè§£æé€»è¾‘ï¼Œé€‚åº”å®é™…æ–‡ä»¶æ ¼å¼
            gene_column_info = {}  # å­˜å‚¨åŸºå› åˆ—ä¿¡æ¯: {åŸºå› å: (åˆ—ç´¢å¼•, NCBI_ID)}
            for i, col_name in enumerate(all_columns):
                # è·³è¿‡ç¬¬ä¸€åˆ—(ModelIDåˆ—)
                if i == 0:
                    continue
                    
                # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œé€‚åº”å®é™…åˆ—åæ ¼å¼
                # ä»å›¾ç‰‡çœ‹ï¼Œåˆ—åæ ¼å¼ä¸º: "TSPAN6 (7105)"ï¼ˆæ³¨æ„æœ‰ç©ºæ ¼ï¼‰
                try:
                    gene_name = col_name.split(' (')[0]
                    ncbi_id = col_name.split(' (')[1].split(')')[0]
                    gene_column_info[gene_name] = (i, ncbi_id)
                except Exception:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œè·³è¿‡æ­¤åˆ—
                    continue
            
            print(f"æˆåŠŸè§£æ {len(gene_column_info)} ä¸ªåŸºå› åˆ—")
            
            # 3. æŸ¥æ‰¾ç›®æ ‡åŸºå› ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            target_gene_upper = target_gene.upper()
            found_gene = None
            for gene_name in gene_column_info:
                if gene_name.upper() == target_gene_upper:
                    found_gene = gene_name
                    break
            
            if found_gene is None:
                available_genes = list(gene_column_info.keys())[:10]
                result['error'] = f"æœªæ‰¾åˆ°åŸºå›  '{target_gene}'ã€‚å¯ç”¨çš„åŸºå› åŒ…æ‹¬: {available_genes}"
                return result
            
            target_col_index, target_ncbi_id = gene_column_info[found_gene]
            print(f"å®šä½åˆ°ç›®æ ‡åŸºå› : {found_gene} (NCBI: {target_ncbi_id})")
            
            # 4. ç¡®å®šéœ€è¦è¯»å–çš„åˆ—
            columns_to_read = [all_columns[0], all_columns[target_col_index]]
            print(f"å°†è¯»å–åˆ—: {columns_to_read}")
            
            # 5. ä½¿ç”¨Daskè¯»å–æŒ‡å®šåˆ—ï¼Œå¢åŠ æ ·æœ¬å¤§å°è§£å†³é•¿åˆ—åé—®é¢˜
            dtypes = {
                all_columns[0]: 'object',    # ModelIDåˆ—ä¸ºå­—ç¬¦ä¸²
                all_columns[target_col_index]: 'float64'  # è¡¨è¾¾å€¼ä¸ºæµ®ç‚¹æ•°
            }
            
            try:
                # æ–¹æ³•1: ä½¿ç”¨Daskå¹¶å¢åŠ æ ·æœ¬å¤§å°
                gene_data = dd.read_csv(
                    file_path,
                    usecols=columns_to_read,
                    dtype=dtypes,
                    sample=50 * 1024 * 1024,  # å¢åŠ æ ·æœ¬å¤§å°åˆ°50MB
                    blocksize='64MB',
                    assume_missing=True
                )
                print("ä½¿ç”¨DaskæˆåŠŸè¯»å–æ•°æ®")
                
            except Exception as e:
                print(f"Daskè¯»å–å¤±è´¥: {e}")
                # æ–¹æ³•2: ä½¿ç”¨Pandasè¯»å–ï¼Œç„¶åè½¬æ¢ä¸ºDask
                print("ä½¿ç”¨Pandasè¯»å–æ•°æ®...")
                try:
                    pandas_data = pd.read_csv(file_path, usecols=columns_to_read)
                    gene_data = dd.from_pandas(pandas_data, npartitions=4)
                    print("ä½¿ç”¨PandasæˆåŠŸè¯»å–å¹¶è½¬æ¢ä¸ºDask DataFrame")
                except Exception as pd_error:
                    result['error'] = f"Pandasè¯»å–ä¹Ÿå¤±è´¥: {pd_error}"
                    return result
            
            # 6. é‡å‘½ååˆ—å¹¶æ·»åŠ åŸºå› ä¿¡æ¯
            gene_data = gene_data.rename(columns={
                all_columns[0]: 'ModelID',
                all_columns[target_col_index]: 'Expression_log'
            })
            
            # æ·»åŠ åŸºå› ç¬¦å·å’ŒNCBIåŸºå› IDåˆ—
            gene_data['Symbol'] = found_gene
            gene_data['NCBI_Gene'] = target_ncbi_id
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåº
            final_columns = ['Symbol', 'NCBI_Gene', 'ModelID', 'Expression_log']
            gene_data = gene_data[final_columns]
            gene_data = gene_data.compute()
            gene_data['Expression'] = gene_data['Expression_log'].apply(lambda x:(2**float(x)-1))
            
            # æ›´æ–°è¿”å›ç»“æœ
            result['data'] = gene_data
            result['gene_found'] = True
            
            return result
            
        except Exception as e:
            result['error'] = f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
            return result
    
    def process_sample_expression(self, gene_info_df, sample_info_df):
        """
        å¤„ç†æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®
        
        Args:
            gene_info_df: åŸºå› è¡¨è¾¾æ•°æ®æ¡†
            sample_info_df: æ ·æœ¬ä¿¡æ¯æ•°æ®æ¡†
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„è¡¨è¾¾æ•°æ®
        """
        if gene_info_df.empty:
            return pd.DataFrame()

        focus_col = ['ModelID', 'PatientID', 'CellLineName', 'StrippedCellLineName', 
                     'DepmapModelType', 'OncotreeLineage', 'OncotreePrimaryDisease', 
                     'OncotreeSubtype', 'OncotreeCode', 'PatientSubtypeFeatures',
                     'PrimaryOrMetastasis','SampleCollectionSite','ModelType',
                     'GrowthPattern','ModelSubtypeFeatures']
        sample_info_subset = sample_info_df[focus_col]
        # åˆå¹¶æ ·æœ¬ä¿¡æ¯

        gene_info_df['ModelID'] = gene_info_df['ModelID'].str.strip()
        
        sample_info_subset['ModelID'] = sample_info_df['ModelID'].str.strip()
        
        merged_df = pd.merge(
            gene_info_df, 
            sample_info_subset, 
            on='ModelID',
            how='left'
        )
        
        return merged_df
    
    def _calculate_expression_stats(self, sample_df):
        """è®¡ç®—è¡¨è¾¾ç»Ÿè®¡ä¿¡æ¯"""
        sample_expressions = sample_df['Expression'].astype(float)
        
        stats = {
            "sample_level": {
                "mean_expression": float(sample_expressions.mean()),
                "median_expression": float(sample_expressions.median()),
                "expression_range": {
                    "min": float(sample_expressions.min()),
                    "max": float(sample_expressions.max())
                },
                "detected_samples": int((sample_expressions > 0).sum()),
                "total_samples": len(sample_expressions)
            }
        }
        return stats
    
    def create_structured_json(self, sample_expression_df, sample_metadata_df):
        """
        åˆ›å»ºç»“æ„åŒ–JSONè¾“å‡º
        
        Args:
            sample_expression_df: ç»†èƒç³»è¡¨è¾¾æ•°æ®
            sample_metadata_df: ç»†èƒç³»æ ·æœ¬ä¿¡æ¯  
            
        Returns:
            str: JSONæ ¼å¼å­—ç¬¦ä¸²
        """
        if sample_expression_df.empty or sample_metadata_df.empty:
            return json.dumps({"error": "æ— æœ‰æ•ˆåŸºå› è¡¨è¾¾æ•°æ®"}, indent=2)
        
        # åŸºç¡€åŸºå› ä¿¡æ¯
        gene_info = {
            "gene_id": sample_expression_df['NCBI_Gene'].iloc[0],
            "gene_name": sample_expression_df['Symbol'].iloc[0],
        }
        # æ ·æœ¬çº§åˆ«è¡¨è¾¾æ•°æ® 
        sample_expression_data = []
        for _, row in sample_expression_df.iterrows():
            sample_data = {
                "ModelID": row['ModelID'],
                "PatientID":  row['PatientID'],
                "expression_value": float(row['Expression']),
                "CellLineName": row['CellLineName'],
                "StrippedCellLineName": row['StrippedCellLineName'],
                "DepmapModelType": row['DepmapModelType'],
                "OncotreeLineage":row['OncotreeLineage'],
                "OncotreePrimaryDisease":row['OncotreePrimaryDisease'],
                "OncotreeSubtype":row['OncotreeSubtype'],
                "OncotreeCode":row['OncotreeCode'],
                "PatientSubtypeFeatures":row['PatientSubtypeFeatures'],
                "PrimaryOrMetastasis":row['PrimaryOrMetastasis'],
                "SampleCollectionSite":row['SampleCollectionSite'],
                "ModelType":row['ModelType'],
                "GrowthPattern":row['GrowthPattern'],
                "ModelSubtypeFeatures":row['ModelSubtypeFeatures']
            }
            sample_expression_data.append(sample_data)

        # è¡¨è¾¾ç»Ÿè®¡ä¿¡æ¯
        expression_stats = self._calculate_expression_stats(sample_expression_df)

        # DepMapç»†èƒç³»è¡¨å‹ä¿¡æ¯
        samples_info_list = []
        columns_to_extract = sample_metadata_df.columns.tolist()
        # éå†æ¯ä¸€è¡Œï¼ˆæ¯ä¸ªæ ·æœ¬ï¼‰
        for index, row in sample_metadata_df.iterrows():
            # ä½¿ç”¨OrderedDictç¡®ä¿é”®çš„é¡ºåº
            sample_dict = OrderedDict()
            # æŒ‰ç…§columns_to_extractçš„é¡ºåºæå–æ•°æ®
            for col in columns_to_extract:
                value = row[col]
                if pd.isna(value):
                    sample_dict[col] = None
                else:
                    sample_dict[col] = value
            samples_info_list.append(sample_dict)

        # æ„å»ºå®Œæ•´æ•°æ®ç»“æ„
        structured_data = OrderedDict([
            ("gene_information", gene_info),
            ("sample_level_expression", {
                "total_samples": len(sample_expression_data),
                "samples": sample_expression_data
            }),
            ("expression_statistics", expression_stats),
            ("cellline_metadata",{'samples':samples_info_list,'sample_count':len(samples_info_list)}),
            ("data_metadata", {
                "data_source": "DepMap Analysis",
                "processing_date": pd.Timestamp.now().strftime("%Y-%m-%d"),
                "units": "TPM (Transcripts Per Million)",
                "gene_id": sample_expression_df['NCBI_Gene'].iloc[0],
                "gene_name":self.genename
            })
        ])
        
        return json.dumps(structured_data, indent=2, ensure_ascii=False)
    
    def parse(self, genename=None):
        """
        ä¸»è§£ææ–¹æ³•ï¼šæ‰§è¡Œå®Œæ•´çš„DepMapæ•°æ®è§£ææµç¨‹
        
        Args:
            genename (str, optional): åŸºå› åå­—ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–åˆå§‹åŒ–å‚æ•°
            
        Returns:
            str: æ ¼å¼åŒ–åçš„JSONå­—ç¬¦ä¸²
        """
        start_time = time.time()
        
        if genename:
            self.genename = genename
        
        if not self.genename:
            raise ValueError("å¿…é¡»æä¾›åŸºå› åç§°ï¼ˆSymbol,å¦‚NECTIN4ï¼‰")
      
        if not all([self.sample_expr_file, self.metadata_file]):
            raise ValueError("å¿…é¡»æä¾›æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶è·¯å¾„")
        
        try:
            print(f"ğŸ” å¼€å§‹è§£æåŸºå›  {self.genename} çš„DepMapæ•°æ®...")
            
            # 1. æå–æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®
            sample_expr_result = self.extract_gene_expression_dask(
                self.sample_expr_file, self.genename
            )
            
            if not sample_expr_result['gene_found']:
                return json.dumps({
                    "error": f"æœªæ‰¾åˆ°åŸºå›  {self.genename} çš„è¡¨è¾¾æ•°æ®",
                    "message": sample_expr_result.get('message', '')
                }, indent=2)
            sample_expr_df = sample_expr_result['data']
            
            # 2. åŠ è½½æ ·æœ¬å…ƒæ•°æ®
            sample_metadata_df = pd.read_csv(self.metadata_file, low_memory=False)
            
            # 3. å¤„ç†æ ·æœ¬è¡¨è¾¾æ•°æ®
            processed_sample_expr = self.process_sample_expression(sample_expr_df, sample_metadata_df)
            
            # 4. ç”Ÿæˆç»“æ„åŒ–JSON
            json_output = self.create_structured_json(
                processed_sample_expr,
                sample_metadata_df
            )
            # è®°å½•å¤„ç†æ—¶é—´
            self.processing_time = time.time() - start_time
            print(f"âœ… åŸºå›  {self.genename} æ•°æ®è§£æå®Œæˆï¼Œè€—æ—¶: {self.processing_time:.2f}ç§’")
            
            self.parsed_data = json.loads(json_output)
            return json_output
            
        except Exception as e:
            error_msg = f"è§£æåŸºå›  {self.genename} æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return json.dumps({"error": error_msg}, indent=2)
    
    def get_processing_time(self):
        """è·å–å¤„ç†æ—¶é—´"""
        return self.processing_time
    
    def get_parsed_data(self):
        """è·å–è§£æåçš„æ•°æ®"""
        return self.parsed_data
    
    def save_to_file(self, filename, genename=None):
        """
        å°†è§£æç»“æœä¿å­˜åˆ°æ–‡ä»¶
        
        Args:
            filename (str): è¾“å‡ºæ–‡ä»¶å
            genename (str, optional): åŸºå› åç§°
        """
        if not self.parsed_data:
            if genename:
                self.parse(genename)
            else:
                self.parse()
        
        json_output = json.dumps(self.parsed_data, indent=2, ensure_ascii=False)
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(json_output)
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
    
    def __str__(self):
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        if self.parsed_data:
            return f"DepMapParser(åŸºå› : {self.genename}, çŠ¶æ€: å·²è§£æ, è€—æ—¶: {self.processing_time:.2f}ç§’)"
        elif self.genename:
            return f"DepMapParser(åŸºå› : {self.genename}, çŠ¶æ€: æœªè§£æ)"
        else:
            return "DepMapParser(çŠ¶æ€: æœªåˆå§‹åŒ–)"