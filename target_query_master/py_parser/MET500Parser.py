import pandas as pd
import json
import os
import time
from collections import OrderedDict

class MET500Parser:
    """
    é¢å‘å¯¹è±¡çš„MET500 (MET500 cohort) æ•°æ®è§£æå™¨
    å°è£…äº†ä»MET500æ•°æ®æ–‡ä»¶æå–åŸºå› è¡¨è¾¾ä¿¡æ¯ã€è§£æå’Œè½¬æ¢çš„åŠŸèƒ½
    """
    
    def __init__(self, ensembl_id=None,
                 genename=None,
                 sample_expr_file=None, 
                 metadata_file=None):
        """
        åˆå§‹åŒ–MET500è§£æå™¨
        
        Args:
            ensembl_id (str, optional): EnsemblåŸºå› ID
            sample_expr_file (str): æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®æ–‡ä»¶è·¯å¾„  
            metadata_file (str): æ ·æœ¬å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.ensembl_id = ensembl_id
        self.genename = genename
        self.sample_expr_file = sample_expr_file
        self.metadata_file = metadata_file
        self.raw_sample_data = None
        self.parsed_data = None
        self.processing_time = None
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        if sample_expr_file and not os.path.exists(sample_expr_file):
            raise FileNotFoundError(f"æ ·æœ¬è¡¨è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {sample_expr_file}")
        if metadata_file and not os.path.exists(metadata_file):
            raise FileNotFoundError(f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")
    
    def extract_gene_data_memory_safe(self, file_path, target_gene):
        """
        å†…å­˜å®‰å…¨çš„åŸºå› æ•°æ®æå–æ–¹æ³•
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            target_gene: ç›®æ ‡åŸºå› ID
            
        Returns:
            dict: åŒ…å«åŸºå› æ•°æ®å’Œå…ƒä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        
        try:
            # é€è¡Œæ‰«ææ–‡ä»¶é¿å…å†…å­˜é—®é¢˜
            target_lines = []
            line_count = 0
            found_count = 0
            
            with open(file_path, 'r') as f:
                # è¯»å–åˆ—å
                columns = next(f).strip().split('\t')
                columns[0] = 'GeneID'
                
                # é€è¡Œæ‰«æç›®æ ‡åŸºå› 
                for line in f:
                    line_count += 1
                    if line_count % 10000 == 0:
                        print(f"ğŸ“ˆ å·²æ‰«æ {line_count} è¡Œï¼Œæ‰¾åˆ° {found_count} ä¸ªåŒ¹é…")
                    
                    parts = line.split('\t', 1)
                    if not parts:
                        continue
                    
                    gene_id_full = parts[0]
                    gene_id = gene_id_full.split('.')[0] if '.' in gene_id_full else gene_id_full
                    
                    if gene_id == target_gene:
                        target_lines.append(line.strip())
                        found_count += 1
            
            if not target_lines:
                return {
                    'data': pd.DataFrame(),
                    'gene_found': False,
                    'message': f'åŸºå›  {target_gene} æœªæ‰¾åˆ°'
                }
            
            # æ„å»ºç»“æœDataFrame
            data_rows = []
            for line in target_lines:
                values = line.split('\t')
                if len(values) > len(columns):
                    print (f"{columns[0]}åˆ—åçš„ä¸ªæ•°å’Œå€¼ä¸åŒ¹é…ï¼Œå€¼çš„ä¸ªæ•°å¤šäºæ ·æœ¬æ•°åŒ¹é…")
                    values = values[:len(columns)]
                elif len(values) < len(columns):
                    print (f"{columns[0]}åˆ—åçš„ä¸ªæ•°å’Œå€¼ä¸åŒ¹é…ï¼Œå€¼çš„ä¸ªæ•°å°‘äºæ ·æœ¬æ•°åŒ¹é…")
                    values.extend([''] * (len(columns) - len(values)))
                data_rows.append(values)
            
            result_df = pd.DataFrame(data_rows, columns=columns)
            
            return {
                'data': result_df,
                'gene_found': True,
                'lines_scanned': line_count,
                'message': f'æˆåŠŸæå–åŸºå›  {target_gene} çš„ {len(result_df)} è¡Œæ•°æ®'
            }
            
        except Exception as e:
            return {
                'data': pd.DataFrame(),
                'gene_found': False,
                'error': str(e)
            }
    
    def process_sample_expression(self, gene_info_df, sample_info_df):
        """
        å¤„ç†æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®
        
        Args:
            gene_info_df: åŸºå› è¡¨è¾¾æ•°æ®æ¡†
            sample_info_df: æ ·æœ¬ä¿¡æ¯æ•°æ®æ¡†
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„è¡¨è¾¾æ•°æ®
        """
        if gene_info_df.empty:
            return pd.DataFrame()
        
        sample_columns = gene_info_df.columns[1:-1]  # è·³è¿‡GeneIDåˆ—
        
        expression_long_list = []
        for sample in sample_columns:
            expression_long_list.append({
                'GeneID': gene_info_df['GeneID'].iloc[0],
                'Sample_id': sample,
                'Expression': gene_info_df[sample].iloc[0]
            })
        
        expression_long = pd.DataFrame(expression_long_list)
     
        # åˆå¹¶æ ·æœ¬ä¿¡æ¯
        sample_info_subset = sample_info_df[['Sample_id', 'sample_type', 'tissue','cohort','biopsy_tissue','tc']].copy()
        
        merged_df = pd.merge(
            expression_long, 
            sample_info_subset, 
            on='Sample_id', 
            how='left'
        )
        
        final_columns = ['GeneID', 'Sample_id', 'sample_type', 'tissue','cohort','biopsy_tissue','tc','Expression']
        merged_df = merged_df[final_columns]
        merged_df = merged_df.rename(columns={'tc':'tumor_content'})
        return merged_df
    
    def _calculate_expression_stats(self, sample_df):
        """è®¡ç®—è¡¨è¾¾ç»Ÿè®¡ä¿¡æ¯"""
        sample_expressions = sample_df['Expression'].astype(float)
        
        stats = {
            "mean_expression": float(sample_expressions.mean()),
            "median_expression": float(sample_expressions.median()),
            "expression_range": {
                "min": float(sample_expressions.min()),
                "max": float(sample_expressions.max())
            },
            "detected_samples": int((sample_expressions > 0).sum()),
            "total_samples": len(sample_expressions)
        }
        return stats
    
    def create_structured_json(self, sample_expression_df,target_gene_name):
        """
        åˆ›å»ºç»“æ„åŒ–JSONè¾“å‡º
        
        Args:
            sample_expression_df: æ ·æœ¬è¡¨è¾¾æ•°æ®
            
        Returns:
            str: JSONæ ¼å¼å­—ç¬¦ä¸²
        """
        if sample_expression_df.empty:
            return json.dumps({"error": "æ— æœ‰æ•ˆåŸºå› è¡¨è¾¾æ•°æ®"}, indent=2)
        
        # åŸºç¡€åŸºå› ä¿¡æ¯
        gene_info = {
            "gene_id": sample_expression_df['GeneID'].iloc[0],
            "gene_name": target_gene_name,
        }
        
        # æ ·æœ¬çº§åˆ«è¡¨è¾¾æ•°æ®
        sample_expression_data = []
        for _, row in sample_expression_df.iterrows():
            sample_data = {
                "sample_id": row['Sample_id'],
                "expression_value": float(row['Expression']),
                'sample_type':row['sample_type'],
                'tissue':row['tissue'],
                'cohort':row['cohort'],
                'biopsy_tissue':row['biopsy_tissue'],
                'tumor_content':row['tumor_content']
            }
            sample_expression_data.append(sample_data)
        
        # è¡¨è¾¾ç»Ÿè®¡ä¿¡æ¯
        expression_stats = self._calculate_expression_stats(sample_expression_df)
        
        # æ„å»ºå®Œæ•´æ•°æ®ç»“æ„
        structured_data = OrderedDict([
            ("gene_information", gene_info),
            ("sample_level_expression", {
                "total_samples": len(sample_expression_data),
                "samples": sample_expression_data
            }),
            ("expression_statistics", expression_stats),
            ("data_metadata", {
                "data_source": "MET500 Analysis",
                "processing_date": pd.Timestamp.now().strftime("%Y-%m-%d"),
                "units": "FPKM (Fragments Per Kilobase of exon model per Million mapped fragments)",
                "ensembl_id": self.ensembl_id,
                "gene_name":self.genename
            })
        ])
        
        return json.dumps(structured_data, indent=2, ensure_ascii=False)
    
    def parse(self, ensembl_id=None):
        """
        ä¸»è§£ææ–¹æ³•ï¼šæ‰§è¡Œå®Œæ•´çš„GTExæ•°æ®è§£ææµç¨‹
        
        Args:
            ensembl_id (str, optional): åŸºå› IDï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–åˆå§‹åŒ–å‚æ•°
            
        Returns:
            str: æ ¼å¼åŒ–åçš„JSONå­—ç¬¦ä¸²
        """
        start_time = time.time()
        
        if ensembl_id:
            self.ensembl_id = ensembl_id
        
        if not self.ensembl_id:
            raise ValueError("å¿…é¡»æä¾›EnsemblåŸºå› ID")
        
        if not all([self.sample_expr_file, self.metadata_file]):
            raise ValueError("å¿…é¡»æä¾›æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶è·¯å¾„")        
        
        try:
            print(f"ğŸ” å¼€å§‹è§£æåŸºå›  {self.ensembl_id} çš„MET500æ•°æ®...")
            
            # 1. æå–æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®
            sample_expr_result = self.extract_gene_data_memory_safe(
                self.sample_expr_file, self.ensembl_id
            )
            
            if not sample_expr_result['gene_found']:
                return json.dumps({
                    "error": f"æœªæ‰¾åˆ°åŸºå›  {self.ensembl_id} çš„è¡¨è¾¾æ•°æ®",
                    "message": sample_expr_result.get('message', '')
                }, indent=2)
            
            sample_expr_df = sample_expr_result['data']

            
            # 2. åŠ è½½æ ·æœ¬å…ƒæ•°æ®
            sample_metadata_df = pd.read_csv(self.metadata_file, sep='\t', low_memory=False)
            
            # 3. å¤„ç†æ ·æœ¬è¡¨è¾¾æ•°æ®
            processed_sample_expr = self.process_sample_expression(sample_expr_df, sample_metadata_df)

            # 4. ç”Ÿæˆç»“æ„åŒ–JSON
            json_output = self.create_structured_json(
                processed_sample_expr,
                self.genename
            )
            # è®°å½•å¤„ç†æ—¶é—´
            self.processing_time = time.time() - start_time
            print(f"âœ… åŸºå›  {self.ensembl_id} æ•°æ®è§£æå®Œæˆï¼Œè€—æ—¶: {self.processing_time:.2f}ç§’")
            
            self.parsed_data = json.loads(json_output)
            return json_output
            
        except Exception as e:
            error_msg = f"è§£æåŸºå›  {self.ensembl_id} æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return json.dumps({"error": error_msg}, indent=2)
    
    def get_processing_time(self):
        """è·å–å¤„ç†æ—¶é—´"""
        return self.processing_time
    
    def get_parsed_data(self):
        """è·å–è§£æåçš„æ•°æ®"""
        return self.parsed_data
    
    def save_to_file(self, filename, ensembl_id=None):
        """
        å°†è§£æç»“æœä¿å­˜åˆ°æ–‡ä»¶
        
        Args:
            filename (str): è¾“å‡ºæ–‡ä»¶å
            ensembl_id (str, optional): åŸºå› ID
        """
        if not self.parsed_data:
            if ensembl_id:
                self.parse(ensembl_id)
            else:
                self.parse()
        
        json_output = json.dumps(self.parsed_data, indent=2, ensure_ascii=False)
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(json_output)
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
    
    def __str__(self):
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        if self.parsed_data:
            return f"MET500Parser(åŸºå› : {self.ensembl_id}, çŠ¶æ€: å·²è§£æ, è€—æ—¶: {self.processing_time:.2f}ç§’)"
        elif self.ensembl_id:
            return f"MET500Parser(åŸºå› : {self.ensembl_id}, çŠ¶æ€: æœªè§£æ)"
        else:
            return "MET500Parser(çŠ¶æ€: æœªåˆå§‹åŒ–)"