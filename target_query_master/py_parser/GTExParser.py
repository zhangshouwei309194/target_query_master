import pandas as pd
import json
import os
import time
from collections import OrderedDict

class GTExParser:
    """
    é¢å‘å¯¹è±¡çš„GTEx (Genotype-Tissue Expression) æ•°æ®è§£æå™¨
    å°è£…äº†ä»GTExæ•°æ®æ–‡ä»¶æå–åŸºå› è¡¨è¾¾ä¿¡æ¯ã€è§£æå’Œè½¬æ¢çš„åŠŸèƒ½
    """
    
    def __init__(self, ensembl_id=None, 
                 sample_expr_file=None, 
                 tissue_expr_file=None, 
                 metadata_file=None):
        """
        åˆå§‹åŒ–GTExè§£æå™¨
        
        Args:
            ensembl_id (str, optional): EnsemblåŸºå› ID
            sample_expr_file (str): æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®æ–‡ä»¶è·¯å¾„
            tissue_expr_file (str): ç»„ç»‡æ°´å¹³è¡¨è¾¾æ•°æ®æ–‡ä»¶è·¯å¾„  
            metadata_file (str): æ ·æœ¬å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.ensembl_id = ensembl_id
        self.sample_expr_file = sample_expr_file
        self.tissue_expr_file = tissue_expr_file
        self.metadata_file = metadata_file
        self.raw_sample_data = None
        self.raw_tissue_data = None
        self.parsed_data = None
        self.processing_time = None
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        if sample_expr_file and not os.path.exists(sample_expr_file):
            raise FileNotFoundError(f"æ ·æœ¬è¡¨è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {sample_expr_file}")
        if tissue_expr_file and not os.path.exists(tissue_expr_file):
            raise FileNotFoundError(f"ç»„ç»‡è¡¨è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {tissue_expr_file}")
        if metadata_file and not os.path.exists(metadata_file):
            raise FileNotFoundError(f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")
    
    def extract_gene_data_memory_safe(self, file_path, target_gene):
        """
        å†…å­˜å®‰å…¨çš„åŸºå› æ•°æ®æå–æ–¹æ³•
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            target_gene: ç›®æ ‡åŸºå› ID
            use_cluster: æ˜¯å¦ä½¿ç”¨åˆ†å¸ƒå¼é›†ç¾¤
            
        Returns:
            dict: åŒ…å«åŸºå› æ•°æ®å’Œå…ƒä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        client = None
        
        try:
            # é€è¡Œæ‰«ææ–‡ä»¶é¿å…å†…å­˜é—®é¢˜
            target_lines = []
            line_count = 0
            found_count = 0
            
            with open(file_path, 'r') as f:
                for _ in range(2):  # è·³è¿‡GCTæ–‡ä»¶å¤´
                    next(f)
                    line_count += 1
                
                # è¯»å–åˆ—å
                columns = next(f).strip().split('\t')
                
                # é€è¡Œæ‰«æç›®æ ‡åŸºå› 
                for line in f:
                    line_count += 1
                    if line_count % 1000000 == 0:
                        print(f"ğŸ“ˆ å·²æ‰«æ {line_count} è¡Œï¼Œæ‰¾åˆ° {found_count} ä¸ªåŒ¹é…")
                    
                    parts = line.split('\t', 1)
                    if not parts:
                        continue
                    
                    gene_id_full = parts[0]
                    gene_id = gene_id_full.split('.')[0] if '.' in gene_id_full else gene_id_full
                    
                    if gene_id == target_gene:
                        target_lines.append(line.strip())
                        found_count += 1
            
            if not target_lines:
                return {
                    'data': pd.DataFrame(),
                    'gene_found': False,
                    'message': f'åŸºå›  {target_gene} æœªæ‰¾åˆ°'
                }
            
            # æ„å»ºç»“æœDataFrame
            data_rows = []
            for line in target_lines:
                values = line.split('\t')
                if len(values) > len(columns):
                    values = values[:len(columns)]
                elif len(values) < len(columns):
                    values.extend([''] * (len(columns) - len(values)))
                data_rows.append(values)
            
            result_df = pd.DataFrame(data_rows, columns=columns)
            
            return {
                'data': result_df,
                'gene_found': True,
                'lines_scanned': line_count,
                'message': f'æˆåŠŸæå–åŸºå›  {target_gene} çš„ {len(result_df)} è¡Œæ•°æ®'
            }
            
        except Exception as e:
            return {
                'data': pd.DataFrame(),
                'gene_found': False,
                'error': str(e)
            }
    
    def process_sample_expression(self, gene_info_df, sample_info_df):
        """
        å¤„ç†æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®
        
        Args:
            gene_info_df: åŸºå› è¡¨è¾¾æ•°æ®æ¡†
            sample_info_df: æ ·æœ¬ä¿¡æ¯æ•°æ®æ¡†
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„è¡¨è¾¾æ•°æ®
        """
        if gene_info_df.empty:
            return pd.DataFrame()
        
        sample_columns = gene_info_df.columns[2:-1]  # è·³è¿‡Name, Descriptionå’ŒGeneIDåˆ—
        
        expression_long_list = []
        for sample in sample_columns:
            expression_long_list.append({
                'Name': gene_info_df['Name'].iloc[0],
                'Description': gene_info_df['Description'].iloc[0],
                'Sample': sample,
                'Expression': gene_info_df[sample].iloc[0]
            })
        
        expression_long = pd.DataFrame(expression_long_list)
        
        # åˆå¹¶æ ·æœ¬ä¿¡æ¯
        sample_info_subset = sample_info_df[['SAMPID', 'SMTS', 'SMTSD']].copy()
        
        expression_long['Sample_Clean'] = expression_long['Sample'].str.strip()
        sample_info_subset['SAMPID_Clean'] = sample_info_subset['SAMPID'].str.strip()
        
        merged_df = pd.merge(
            expression_long, 
            sample_info_subset, 
            left_on='Sample_Clean', 
            right_on='SAMPID_Clean', 
            how='left'
        )
        
        merged_df.drop(['Sample_Clean', 'SAMPID_Clean'], axis=1, inplace=True)
        final_columns = ['Name', 'Description', 'Sample', 'Expression', 'SAMPID', 'SMTS', 'SMTSD']
        
        return merged_df[final_columns]
    
    def process_tissue_expression(self, median_gene_info_df, target_gene):
        """
        å¤„ç†ç»„ç»‡ç‰¹å¼‚æ€§è¡¨è¾¾æ•°æ®
        
        Args:
            median_gene_info_df: ç»„ç»‡è¡¨è¾¾æ•°æ®æ¡†
            target_gene: ç›®æ ‡åŸºå› ID
            
        Returns:
            dict: åŒ…å«ç»„ç»‡è¡¨è¾¾å’Œç‰¹å¼‚æ€§ä¿¡æ¯å­—å…¸
        """
        median_gene_info_df['GeneID'] = median_gene_info_df['Name'].str.split('.').str[0]
        target_gene_info_df = median_gene_info_df[median_gene_info_df['GeneID'] == target_gene]
        target_gene_info_df = target_gene_info_df.reset_index(drop=True)
        
        if target_gene_info_df.empty:
            return {'Tissue_expression': pd.DataFrame(), 'Tissue_specificity': {}}
        
        tissue_specificity_columns = target_gene_info_df.columns[2:5]
        tissue_columns = target_gene_info_df.columns[5:-1] 
        
        expression_long_list = []
        for tissue in tissue_columns:
            expression_long_list.append({
                'Name': target_gene_info_df['Name'].iloc[0],
                'Description': target_gene_info_df['Description'].iloc[0],
                'Tissue': tissue,
                'Expression': target_gene_info_df[tissue].iloc[0]
            })
        
        expression_long_df = pd.DataFrame(expression_long_list)

        # ç»„ç»‡ç‰¹å¼‚æ€§ä¿¡æ¯
        tissue_specificity_dict = {}
        for tissue_specificity in tissue_specificity_columns:
            tissue_specificity_dict[tissue_specificity] = target_gene_info_df[tissue_specificity].iloc[0]

        return {
            'Tissue_expression': expression_long_df,
            'Tissue_specificity': tissue_specificity_dict
        }
    
    def _categorize_expression(self, expression_value):
        """æ ¹æ®è¡¨è¾¾å€¼åˆ†ç±»è¡¨è¾¾æ°´å¹³"""
        if expression_value == 0:
            return "Not detected"
        elif expression_value < 1:
            return "Low"
        elif expression_value < 10:
            return "Medium"
        else:
            return "High"
    
    def _calculate_expression_stats(self, sample_df, tissue_df):
        """è®¡ç®—è¡¨è¾¾ç»Ÿè®¡ä¿¡æ¯"""
        sample_expressions = sample_df['Expression'].astype(float)
        tissue_expressions = tissue_df['Expression'].astype(float)
        
        stats = {
            "sample_level": {
                "mean_expression": float(sample_expressions.mean()),
                "median_expression": float(sample_expressions.median()),
                "expression_range": {
                    "min": float(sample_expressions.min()),
                    "max": float(sample_expressions.max())
                },
                "detected_samples": int((sample_expressions > 0).sum()),
                "total_samples": len(sample_expressions)
            },
            "tissue_level": {
                "mean_expression": float(tissue_expressions.mean()),
                "median_expression": float(tissue_expressions.median()),
                "expression_range": {
                    "min": float(tissue_expressions.min()),
                    "max": float(tissue_expressions.max())
                },
                "highly_expressed_tissues": int((tissue_expressions >= 10).sum())
            }
        }
        
        return stats
    
    def create_structured_json(self, sample_expression_df, tissue_expression_df, tissue_specificity_dict):
        """
        åˆ›å»ºç»“æ„åŒ–JSONè¾“å‡º[9](@ref)
        
        Args:
            sample_expression_df: æ ·æœ¬è¡¨è¾¾æ•°æ®
            tissue_expression_df: ç»„ç»‡è¡¨è¾¾æ•°æ®  
            tissue_specificity_dict: ç»„ç»‡ç‰¹å¼‚æ€§å­—å…¸
            
        Returns:
            str: JSONæ ¼å¼å­—ç¬¦ä¸²
        """
        if sample_expression_df.empty or tissue_expression_df.empty:
            return json.dumps({"error": "æ— æœ‰æ•ˆåŸºå› è¡¨è¾¾æ•°æ®"}, indent=2)
        
        # åŸºç¡€åŸºå› ä¿¡æ¯
        gene_info = {
            "gene_id": sample_expression_df['Name'].iloc[0],
            "gene_name": sample_expression_df['Description'].iloc[0],
        }
        
        # æ ·æœ¬çº§åˆ«è¡¨è¾¾æ•°æ®
        sample_expression_data = []
        for _, row in sample_expression_df.iterrows():
            sample_data = {
                "sample_id": row['Sample'],
                "expression_value": float(row['Expression']),
                "tissue_type": row['SMTS'],
                "tissue_subtype": row['SMTSD'],
                "sample_accession": row['SAMPID']
            }
            sample_expression_data.append(sample_data)
        
        # ç»„ç»‡çº§åˆ«è¡¨è¾¾æ•°æ®
        tissue_expression_data = []
        for _, row in tissue_expression_df.iterrows():
            tissue_data = {
                "tissue_name": row['Tissue'],
                "expression_value": float(row['Expression']),
                "expression_category": self._categorize_expression(float(row['Expression']))
            }
            tissue_expression_data.append(tissue_data)
        
        # ç»„ç»‡ç‰¹å¼‚æ€§ä¿¡æ¯
        specificity_info = {
            "tau_score": float(tissue_specificity_dict.get('Tau', 0)),
            "specificity_type": tissue_specificity_dict.get('Specificity_Type', 'Unknown'),
            "specific_tissues": tissue_specificity_dict.get('Specific_Tissues', '')
        }
        
        # è¡¨è¾¾ç»Ÿè®¡ä¿¡æ¯
        expression_stats = self._calculate_expression_stats(sample_expression_df, tissue_expression_df)
        
        # æ„å»ºå®Œæ•´æ•°æ®ç»“æ„
        structured_data = OrderedDict([
            ("gene_information", gene_info),
            ("sample_level_expression", {
                "total_samples": len(sample_expression_data),
                "samples": sample_expression_data
            }),
            ("tissue_level_expression", {
                "tissues_analyzed": len(tissue_expression_data),
                "tissue_data": tissue_expression_data
            }),
            ("tissue_specificity_analysis", specificity_info),
            ("expression_statistics", expression_stats),
            ("data_metadata", {
                "data_source": "GTEx Analysis",
                "processing_date": pd.Timestamp.now().strftime("%Y-%m-%d"),
                "units": "TPM (Transcripts Per Million)",
                "ensembl_id": self.ensembl_id
            })
        ])
        
        return json.dumps(structured_data, indent=2, ensure_ascii=False)
    
    def parse(self, ensembl_id=None, strategy='auto'):
        """
        ä¸»è§£ææ–¹æ³•ï¼šæ‰§è¡Œå®Œæ•´çš„GTExæ•°æ®è§£ææµç¨‹
        
        Args:
            ensembl_id (str, optional): åŸºå› IDï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–åˆå§‹åŒ–å‚æ•°
            strategy (str): å¤„ç†ç­–ç•¥ ('auto', 'safe', 'dask')
            
        Returns:
            str: æ ¼å¼åŒ–åçš„JSONå­—ç¬¦ä¸²
        """
        start_time = time.time()
        
        if ensembl_id:
            self.ensembl_id = ensembl_id
        
        if not self.ensembl_id:
            raise ValueError("å¿…é¡»æä¾›EnsemblåŸºå› ID")
        
        if not all([self.sample_expr_file, self.tissue_expr_file, self.metadata_file]):
            raise ValueError("å¿…é¡»æä¾›æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶è·¯å¾„")
        
        try:
            print(f"ğŸ” å¼€å§‹è§£æåŸºå›  {self.ensembl_id} çš„GTExæ•°æ®...")
            
            # 1. æå–æ ·æœ¬æ°´å¹³è¡¨è¾¾æ•°æ®
            sample_expr_result = self.extract_gene_data_memory_safe(
                self.sample_expr_file, self.ensembl_id
            )
            
            if not sample_expr_result['gene_found']:
                return json.dumps({
                    "error": f"æœªæ‰¾åˆ°åŸºå›  {self.ensembl_id} çš„è¡¨è¾¾æ•°æ®",
                    "message": sample_expr_result.get('message', '')
                }, indent=2)
            
            sample_expr_df = sample_expr_result['data']

            
            # 2. åŠ è½½æ ·æœ¬å…ƒæ•°æ®
            sample_metadata_df = pd.read_csv(self.metadata_file, sep='\t', low_memory=False)
            
            # 3. å¤„ç†æ ·æœ¬è¡¨è¾¾æ•°æ®
            processed_sample_expr = self.process_sample_expression(sample_expr_df, sample_metadata_df)
            
            # 4. å¤„ç†ç»„ç»‡è¡¨è¾¾æ•°æ®
            tissue_expr_df = pd.read_csv(self.tissue_expr_file, sep='\t')
            tissue_result = self.process_tissue_expression(tissue_expr_df, self.ensembl_id)
            # 5. ç”Ÿæˆç»“æ„åŒ–JSON
            json_output = self.create_structured_json(
                processed_sample_expr,
                tissue_result['Tissue_expression'],
                tissue_result['Tissue_specificity']
            )
            # è®°å½•å¤„ç†æ—¶é—´
            self.processing_time = time.time() - start_time
            print(f"âœ… åŸºå›  {self.ensembl_id} æ•°æ®è§£æå®Œæˆï¼Œè€—æ—¶: {self.processing_time:.2f}ç§’")
            
            self.parsed_data = json.loads(json_output)
            return json_output
            
        except Exception as e:
            error_msg = f"è§£æåŸºå›  {self.ensembl_id} æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return json.dumps({"error": error_msg}, indent=2)
    
    def get_processing_time(self):
        """è·å–å¤„ç†æ—¶é—´"""
        return self.processing_time
    
    def get_parsed_data(self):
        """è·å–è§£æåçš„æ•°æ®"""
        return self.parsed_data
    
    def save_to_file(self, filename, ensembl_id=None):
        """
        å°†è§£æç»“æœä¿å­˜åˆ°æ–‡ä»¶
        
        Args:
            filename (str): è¾“å‡ºæ–‡ä»¶å
            ensembl_id (str, optional): åŸºå› ID
        """
        if not self.parsed_data:
            if ensembl_id:
                self.parse(ensembl_id)
            else:
                self.parse()
        
        json_output = json.dumps(self.parsed_data, indent=2, ensure_ascii=False)
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(json_output)
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
    
    def __str__(self):
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        if self.parsed_data:
            return f"GTExParser(åŸºå› : {self.ensembl_id}, çŠ¶æ€: å·²è§£æ, è€—æ—¶: {self.processing_time:.2f}ç§’)"
        elif self.ensembl_id:
            return f"GTExParser(åŸºå› : {self.ensembl_id}, çŠ¶æ€: æœªè§£æ)"
        else:
            return "GTExParser(çŠ¶æ€: æœªåˆå§‹åŒ–)"